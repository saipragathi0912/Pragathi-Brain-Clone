Models - can't understand text data (can only munch numbers). There are ways to convert text to numerical data. This chapter will be predominantly discussing about that.
The sequence of text data -> continuous valued vectors -> Embedding. 
Embedding is a mapping established from the data of interest (audio, video or text documents) to a vector space. One of the most popular word embedding techniques -> Word2Vec
Word2Vec assumes the words that appear in similar context has similar meanings.

The remaining part of the chapter 2 is mainly concentrated on implementation of Tokenizers. 